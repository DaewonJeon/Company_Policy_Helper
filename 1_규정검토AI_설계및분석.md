# [프로젝트 2] 사내 규정/계약서 검토 AI 비서: 설계 및 분석

> **목표**: "기술(AI)을 활용하여 비정형 데이터의 비효율을 해결하고, 조직의 '판단 비용'을 낮추는 RAG 시스템 구축"
> **독자**: 채용 담당자, AI 도입을 고민하는 의사결정권자, 그리고 이 프로젝트를 실행할 개발자

---

## 1. 비즈니스 개요 및 문제 정의 (Why)

이 프로젝트는 단순한 "챗봇 만들기"가 아닙니다. 기업이 가진 가장 소중한 자산인 **'지식(문서)'을 활용 가능한 상태로 만드는 Digital Transformation(DX)** 과정입니다.

### 1.1 문제 상황 (Pain Point)
신입사원이나 타 부서 직원이 규정 관련 질문을 할 때마다 담당자가 겪는 고충입니다.

| 문제점 | 세부 내용 | 비즈니스 손실 |
|:---:|---|---|
| **정보의 파편화** | 규정집, 노무 가이드, 지난달 공지가 PDF, Word, 이메일에 흩어져 있음. | 정보 검색에만 업무 시간의 **20%** 소요 (맥킨지 리포트 인용) |
| **반복 답변 피로** | "경조사 휴가 며칠인가요?", "식대 한도가 얼마죠?" 같은 단순 질문 반복. | 담당자(HR/총무)의 **업무 몰입도 저하** 및 고급 업무 방해 |
| **휴먼 리스크** | 담당자의 기억에 의존하여 답변하다가, 개정된 규정을 놓치고 잘못 안내함. | 법적 리스크 발생 가능성 |

### 1.2 해결 솔루션 (Solution): RAG (검색 증강 생성)
**RAG (Retrieval-Augmented Generation)** 기술을 도입합니다.
1.  회사 규정집(PDF)을 AI에게 미리 '지식'으로 주입합니다.
2.  사용자가 질문하면, AI가 관련 페이지를 먼저 찾아서 읽습니다.
3.  찾은 내용을 근거로 정확한 답변을 생성합니다. (단순 환각 방지)

### 1.3 기대 효과 (ROI)
- **정량적 효과**: 단순 질의응답 시간 **95% 단축**. 담당자는 "규정집 4페이지를 보세요"라고 말하는 대신, AI 링크만 전달하면 됨.
- **정성적 효과**: **'물어보면 1초 만에 대답해주는 비서'** 도입으로 임직원 만족도 상승. 데이터 기반의 투명한 의사결정 문화 정착.

---

## 2. 기술적 접근 및 아키텍처 (How)

RAG는 LLM(거대언어모델) 분야에서 가장 실용적인 기술 아키텍처입니다.

### 2.1 아키텍처 다이어그램

```mermaid
flowchart LR
    subgraph Storage [지식 저장소 (Knowledge Base)]
        Docs[규정집 PDF] --> Loader[Document Loader]
        Loader --> Splitter[텍스트 쪼개기 (Chunking)]
        Splitter --> Embed[임베딩 (Vector화)]
        Embed --> VectorDB[(Vector DB\nChroma/FAISS)]
    end

    subgraph Service [서비스 (RAG Pipeline)]
        User(사용자 질문) --> Query[질문 임베딩]
        Query <-->|유사도 검색| VectorDB
        VectorDB -->|관련 문서 조각 반환| Context[검색된 근거 자료]
        
        Context --> LLM[GPT-4o / Claude]
        User --> LLM
        LLM --> Answer[최종 답변 생성]
    end
```

### 2.2 기술 스택 선정 이유

| 기술 | 역할 | 선정 근거 (면접 답변용) |
|---|---|---|
| **LangChain** | Framework | LLM과 문서를 연결하는 파이프라인(Chain)을 가장 쉽게 구축할 수 있는 표준 프레임워크. |
| **Streamlit** | Chat UI | 챗GPT와 같은 '채팅형 인터페이스'를 파이썬만으로 빠르게 구현 가능. |
| **OpenAI (GPT-4o)** | LLM (두뇌) | 한국어 문맥 이해도가 가장 높고, 복잡한 규정 해석 능력이 탁월함. (비용 효율적인 gpt-4o-mini 사용 가능) |
| **ChromaDB** | Vector Store | 별도의 서버 설치 없이 로컬 파일로 저장되는 가벼운 벡터 DB. 초기 구축 및 테스트에 최적. |

---

## 3. 핵심 기능 논리 설계 (Logic)

사용자는 단순해 보이지만, 내부는 2단계 프로세스("학습"과 "검색")로 나뉩니다.

### 3.1 학습 단계 (Ingestion) - "책 읽히기"
1.  **Load**: PDF의 텍스트를 추출합니다.
2.  **Split**: 100페이지짜리 통째로 넣으면 AI가 이해하기 힘듭니다. 문맥이 끊기지 않게 **문단 단위(Chunk)**로 잘게 쪼갭니다. (예: 500자 단위)
3.  **Embed**: 쪼개진 텍스트를 AI가 이해하는 **숫자 형태(Vector)**로 변환하여 DB에 저장합니다.

### 3.2 검색 및 답변 단계 (RAG) - "시험 보기"
1.  사용자가 "경조사 휴가 며칠?"이라고 묻습니다.
2.  AI는 DB에서 '경조사', '휴가'와 **의미적으로 가장 가까운** 문서 조각 3개를 찾아옵니다. (Keyword 검색이 아닌 의미 검색)
3.  찾아온 조각을 프롬프트에 끼워 넣습니다.
    > *"다음 문서를 바탕으로 답변해. 문서는 경조사 규정 14조야. 질문은 휴가 며칠이냐는 거야."*
4.  LLM이 최종 답변을 작성합니다. *"규정 14조에 따르면 본인 결혼 시 5일입니다."*

### 3.3 환각(Hallucination) 방지 전략
현업에서 가장 중요한 것은 **"거짓말을 하지 않는 것"**입니다.
*   **Prompt Engineering**: "문서에 없는 내용이면 '모르겠습니다'라고 대답해."라는 지시어를 명확히 포함합니다.
*   **Source Citation**: 답변 끝에 반드시 **(출처: 인사규정.pdf 14페이지)**를 표시하도록 설계합니다.

---

## 4. 확장성 및 배포 전략

### 4.1 데이터 보안 (Security)
*   **Local LLM**: 사내 보안이 극도로 중요하다면, 데이터를 외부(OpenAI)로 보내지 않고 사내 서버에 구축된 오픈소스 모델(Llama 3 등)로 교체 가능하도록 설계했습니다. (LangChain의 장점)

### 4.2 유지보수
*   규정이 개정되면? -> 새로운 PDF만 덮어씌우고 `ingest.py`를 다시 실행하면 끝. (재학습 비용 0원)

---
> **결론**: 이 프로젝트는 단순 기술 도입을 넘어, **"회사의 지식 자산을 시스템화"**하는 AI Ops의 첫걸음입니다.
