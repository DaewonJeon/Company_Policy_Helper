import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# 1. í™˜ê²½ ì„¤ì • ë¡œë“œ
load_dotenv()

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
DATA_PATH = "./data"
DB_PATH = "./chroma_db"  # ë²¡í„° DBê°€ ì €ì¥ë  í´ë”

def ingest_docs():
    print("ğŸ”„ ë¬¸ì„œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # 2. PDF íŒŒì¼ ë¡œë“œ
    documents = []
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print("âš ï¸ data í´ë”ê°€ ì—†ì–´ ìƒì„±í–ˆìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return

    files = [f for f in os.listdir(DATA_PATH) if f.endswith('.pdf')]
    if not files:
        print("âš ï¸ data í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for file in files:
        loader = PyPDFLoader(os.path.join(DATA_PATH, file))
        documents.extend(loader.load())
        print(f"   - {file} ë¡œë“œ ì™„ë£Œ ({len(documents)} í˜ì´ì§€)")

    # 3. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    # ë¬¸ë§¥ ìœ ì§€ë¥¼ ìœ„í•´ 1000ì ë‹¨ìœ„ë¡œ ìë¥´ê³ , 200ìëŠ” ê²¹ì¹˜ê²Œ(overlap) ì„¤ì •
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    splits = text_splitter.split_documents(documents)
    print(f"ğŸ“Š ì´ {len(splits)}ê°œì˜ ì§€ì‹ ì¡°ê°ìœ¼ë¡œ ë¶„í•´ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 4. ë²¡í„° DB ì €ì¥ (Embeddings)
    # OpenAIì˜ ì„ë² ë”© ëª¨ë¸(text-embedding-3-small) ì‚¬ìš© - ì €ë ´í•˜ê³  ì„±ëŠ¥ ì¢‹ìŒ
    print("ğŸ’¾ ë²¡í„° DBì— ì €ì¥ ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=OpenAIEmbeddings(model="text-embedding-3-small"),
        persist_directory=DB_PATH
    )
    
    print("âœ… í•™ìŠµ ì™„ë£Œ! 'chroma_db' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    ingest_docs()
